{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "class SpiralDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dir, train=True):\n",
    "        # code for generating this dataset is in spiral_dataset_generator.ipynb\n",
    "        super().__init__()\n",
    "\n",
    "        dataset_file = os.path.join(\n",
    "            dir, 'spiral', 'train_dataset.txt' if train else 'test_dataset.txt')\n",
    "\n",
    "        self.data, self.targets = [], []\n",
    "\n",
    "        with open(dataset_file, 'r') as f:\n",
    "            for line in f:\n",
    "                data_x, data_y, target = line.split(' ')\n",
    "                data_x, data_y = float(data_x), float(data_y)\n",
    "                self.data.append([data_x, data_y, math.sin(data_x), math.sin(data_y)])\n",
    "                self.targets.append(float(target))\n",
    "\n",
    "        self.data, self.targets = torch.tensor(\n",
    "            self.data), torch.tensor(self.targets)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # print(type(self.targets[index]))\n",
    "        return self.data[index], self.targets[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.targets)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "dir=\"datasets\"\n",
    "trainset = SpiralDataset(dir, train=True)\n",
    "testset = SpiralDataset(dir, train=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "    trainset, batch_size=64, shuffle=True, num_workers=1, pin_memory=True)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    testset, batch_size=64, shuffle=False, num_workers=1, pin_memory=True)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "class SpiralModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Linear(4, 12, bias=False), torch.nn.Tanh())\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Linear(12, 24, bias=False), torch.nn.Tanh())\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Linear(24, 24, bias=False), torch.nn.Tanh())\n",
    "        self.layer4 = nn.Sequential(\n",
    "            nn.Linear(24, 32, bias=False), torch.nn.Tanh())\n",
    "        self.layer5 = nn.Sequential(\n",
    "            nn.Linear(32, 2, bias=False), torch.nn.Tanh())\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = x.float()\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = self.layer5(out)\n",
    "        return out\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "def train(model, train_loader, batch_size, optimizer, epoch):\n",
    "    model.train()\n",
    "    loss_per_batch = []\n",
    "\n",
    "    acc_train_per_batch = []\n",
    "    correct = 0\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output = model(data)\n",
    "        output = F.log_softmax(output, dim=1)\n",
    "\n",
    "        loss = F.nll_loss(output, target.long())\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_per_batch.append(loss.item())\n",
    "\n",
    "        # save accuracy:\n",
    "        # get the index of the max log-probability\n",
    "        pred = output.max(1, keepdim=True)[1]\n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "        acc_train_per_batch.append(\n",
    "            100. * correct / ((batch_idx+1)*batch_size))\n",
    "\n",
    "        # if batch_idx % 1000 == 0:\n",
    "        #     print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}, Accuracy: {:.0f}%, Learning rate: {:.6f}'.format(\n",
    "        #         epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "        #         100. * batch_idx / len(train_loader), loss.item(),\n",
    "        #         100. * correct / ((batch_idx + 1) * batch_size),\n",
    "        #         optimizer.param_groups[0]['lr']))\n",
    "\n",
    "    loss_per_epoch = [np.average(loss_per_batch)]\n",
    "    acc_train_per_epoch = [np.average(acc_train_per_batch)]\n",
    "    return (loss_per_epoch, acc_train_per_epoch)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "model = SpiralModel()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=0.001)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "for epoch in range(100):\n",
    "    loss_per_epoch, acc_train_per_epoch_i =  train(\n",
    "        model, train_loader, 64, optimizer, epoch)\n",
    "    if epoch % 10 == 0:\n",
    "        print(acc_train_per_epoch_i)\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/masonwang/anaconda3/envs/lnoise-analysis/lib/python3.8/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 804: forward compatibility was attempted on non supported HW (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448234945/work/c10/cuda/CUDAFunctions.cpp:115.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[48.2444659019366]\n",
      "[63.02338747407107]\n",
      "[84.1808035985282]\n",
      "[91.67852573858434]\n",
      "[88.27870005970593]\n",
      "[92.41918427709443]\n",
      "[91.85762208711428]\n",
      "[91.86411190805723]\n",
      "[88.7281281543977]\n",
      "[94.95233824335386]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "import visualizer"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "demo_loader = torch.utils.data.DataLoader(\n",
    "    trainset, batch_size=len(trainset), num_workers=1, pin_memory=True)\n",
    "x_train, y_train = next(iter(train_loader))\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "visualizer.plot_spiral_dataset(\n",
    "    x_train, y_train, f'Spiral Dataset (noise: 0%)')\n",
    "print(list(y_train).count(0) / len(y_train))\n"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'NOISE_LEVEL' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-1345cbc9b215>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvisualizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_spiral_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf'Spiral Dataset (noise: {NOISE_LEVEL}%)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'NOISE_LEVEL' is not defined"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('lnoise-analysis': conda)"
  },
  "interpreter": {
   "hash": "87d906df2142479f111adbbf4c473c801b6d6d4d551237e12cdc7d4f5a1fce94"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}